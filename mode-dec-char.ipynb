{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一、自己训练模型，采用逻辑回归算法，用于图片识别,准备环境 安装tensorflow 和 python: \n",
    "1、安装Python2.7和pip\n",
    "Python2.7的官方网站：https://www.python.org/getit/\n",
    "pip是Python Package Index，通过pip可以非常方便的查找安装其他软件，\n",
    "2、安装pip的方法如下：https://pip.pypa.io/en/stable/installing/\n",
    "3、安装TensorFlow\n",
    "$ pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "import tensorflow as tf\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二、下载数据首先，我们会下载数据集到本地电脑；所有的图片都是28*28像素的图片，\n",
    "标示为\"A\"到\"J\"（10个分类）。整个数据集合包含大概50000个训练数据和19000个测试数据，\n",
    "所以这样规模的数据集合可以在大多数电脑上较快的完成训练。\n",
    "训练数据文件名是notMNIST_large.tar.gz，测试数据文件名是notMNIST_small.tar.gz。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified ./notMNIST_large.tar.gz\n",
      "Found and verified ./notMNIST_small.tar.gz\n"
     ]
    }
   ],
   "source": [
    "#2.对下载数据进行处理\n",
    "\n",
    "#url = 'http://commondatastorage.googleapis.com/books1000/'\n",
    "url = 'http://cn-static.udacity.com/mlnd/'\n",
    "\n",
    "last_percent_reported = None\n",
    "data_root = '.' # Change me to store data elsewhere\n",
    "\n",
    "#A hook to report the progress of a download. This is mostly intended for users with\n",
    "#slow internet connections. Reports every 5% change in download progress.\n",
    "\n",
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "  global last_percent_reported\n",
    "  percent = int(count * blockSize * 100 / totalSize)\n",
    "\n",
    "  if last_percent_reported != percent:\n",
    "    if percent % 5 == 0:\n",
    "      sys.stdout.write(\"%s%%\" % percent)\n",
    "      sys.stdout.flush()\n",
    "    else:\n",
    "      sys.stdout.write(\".\")\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "    last_percent_reported = percent\n",
    "        \n",
    "def maybe_download(filename, expected_bytes, force=False):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  dest_filename = os.path.join(data_root, filename)\n",
    "  if force or not os.path.exists(dest_filename):\n",
    "    print('Attempting to download:', filename) \n",
    "    filename, _ = urlretrieve(url + filename, dest_filename, reporthook=download_progress_hook)\n",
    "    print('\\nDownload Complete!')\n",
    "  statinfo = os.stat(dest_filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified', dest_filename)\n",
    "  else:\n",
    "    raise Exception('Failed to verify ' + dest_filename + '. Can you get to it with a browser?')\n",
    "  return dest_filename\n",
    "\n",
    "train_filename = maybe_download('notMNIST_large.tar.gz', 247336696)\n",
    "test_filename = maybe_download('notMNIST_small.tar.gz', 8458043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./notMNIST_large already present - Skipping extraction of ./notMNIST_large.tar.gz.\n",
      "['./notMNIST_large/A', './notMNIST_large/B', './notMNIST_large/C', './notMNIST_large/D', './notMNIST_large/E', './notMNIST_large/F', './notMNIST_large/G', './notMNIST_large/H', './notMNIST_large/I', './notMNIST_large/J']\n",
      "./notMNIST_small already present - Skipping extraction of ./notMNIST_small.tar.gz.\n",
      "['./notMNIST_small/A', './notMNIST_small/B', './notMNIST_small/C', './notMNIST_small/D', './notMNIST_small/E', './notMNIST_small/F', './notMNIST_small/G', './notMNIST_small/H', './notMNIST_small/I', './notMNIST_small/J']\n"
     ]
    }
   ],
   "source": [
    "#3.解压数据\n",
    "num_classes = 10\n",
    "np.random.seed(133)\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "  if os.path.isdir(root) and not force:\n",
    "    # You may override by setting force=True.\n",
    "    print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "  else:\n",
    "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "    tar = tarfile.open(filename)\n",
    "    sys.stdout.flush()\n",
    "    tar.extractall(data_root)\n",
    "    tar.close()\n",
    "  data_folders = [\n",
    "    os.path.join(root, d) for d in sorted(os.listdir(root))\n",
    "    if os.path.isdir(os.path.join(root, d))]\n",
    "  if len(data_folders) != num_classes:\n",
    "    raise Exception('Expected %d folders, one per class. Found %d instead.' % (num_classes, len(data_folders)))\n",
    "  print(data_folders)\n",
    "  return data_folders\n",
    "  \n",
    "train_folders = maybe_extract(train_filename)\n",
    "test_folders = maybe_extract(test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6klEQVR4nMWQsU7DQBBEZ8+2KCxFoYMfQKIIP5P0+YKUdCno+YR0KUgDPSVdalPQpUmkIHCkHA0KwreTwjI6+2xExzQn7bu5nTlJx6OznkGgQ3aTYUbHNikPk3gIEoCE3s+PWBEBlKe7VOtou9xjR5KOt4gDq6lGSQCpWo0URRFawyB/hNWzAlO7R3rQQetVDPQHnl/0nYe+3nIAZc9AhX24hHRAOi46YWEfryDlTjXz6am/89u+A6wC5ZvX+g/5aaNGT6jXk82epfsX/QtkeYZRAZiECipOWuFKBBLhBWyhg/u13T1ft+4+AlN3qu9EVbvnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABbklEQVR4nFWRzSsFYRjFf8/7zr2XuBElC/lYKImSQlKkFCXF1t/j/2FBKBIJOzfZYMWGRL42uuZ9H4uZdz7ObubMc86ZcyDFjjotIdbNwHV8lin1+jsSASC61EEGB+Cqp88Jadw6KoG0AJ7zrwhAXHW6QF58R4pvPQmfrvyoT7ycNnoQACECsG6x3dnU0Oy/VnwiHAHSrE2iCaeWK9Tl6Syz7+EvY70ZoGKtFUgumej6q6SXnD1Wm+lVBBLXFpDsefmgxSNsHYsChqG3kDVDczBJq4x1h6ygXkEr509oQq5lqqhYwLHr00C11ZyUDwDfeoTxgDDv8ikanW31er3eJkk64zZM6FVl+5MiDNfZzrHOYEVEJNQz85aXftub24MxLHV7CSsfvkhR1DGFTx0Nl1gteo49Bkun98OYUpzx/jh94Wk8lA4Nc4UpLzAl1b67oOr1ebSkCvMaa7C8xJY4k5du2KMkCnf5lPFEsQHgH7Oc+K0R307/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAfElEQVR4nGP8z4AD/GOawAJj/8WU/AeXZEaXZGRgg0n+2/yXEVXyP9s5hv8Q8IMdi7VwY5kYmNDl/sMl/zH8w9CJoZw6kkj+RPHp/3/Ikn8xw4iBERq2/44gB8J/jk0dSDqZ7JC1/GO6T7SD0I29DKGJCVuSvUKjsB1akgAttDIBo5T3rQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABmElEQVR4nHWSPWsUURSGn3Pv3d2JsxkNgsGxElFQUUglEsEfIEgKkzpt3EbEf2CvjU1aQVKJhZWFWG5hkUJEREQrCQQXs/lQZ+69x2JmjTNu3ubCec9zPi5HHlwbbe/s/tj3Zek9xjjbOZam/bSfJa956fUo7Qn9MwuDG1EANT/fbI5/u5kTp89fSj0WQeCZetWouoyh0oVHhUYQ0+XKnkYN+tWIc845a8SypmWV1/2kQYN+RmoQx+wHNQBS1Elo/Qqd3Y1NAAzva3LiSR2fItGTg7MYaZECiLW80AEW12RUUNV4b4mDSagioxZLCKSXn4Sod5qk0Nn48guX5klUCdAqm1ycTESvZaqsPy20O5vfXJkhafYM+i1DAMP1bb2Pbe55MHbGWmt6w8fkSNMUfAgh+JLndP8bqFbk49UtwnQT5B3o9L8FNXJUWSBWW3BYwLZSDWD0VAYIc+ewLdMZbuXRICFbRY1r+MLtkZbeex/iw+OHZwSQ3h3+PeOoo1frK/9gC8Pe1vfxzn4ROknWz+fd28VSqkP7A+PCyREfucjfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABI0lEQVR4nG1Su04DMRCctffAOS7FkU9IyvxCypR8DBJfg/gDREOdEiFRpkRCioSUFLzRoQhxZy9FxHkXZSuPx7OzHhu4kB/ZV0muGAVUxbwUnjIKUN7xeZmwtMp02/YnpTjXpNDH/FubMA4U2kTtARcGPRasOy0UDmUG2AjEKEuFnk1X0xb4tCSHgWrbgFOGkUOpBnpE0iNxWWULzDD8U0pxf4e5xL25R1mNuUJyvbbNjil0wiM9nsq5o4cVH+fpkzu7qckze8+HoVpopbivxdKrFwWP8k1o/YrsD0lcqwze3tGZbJUSzRamXK1AI86SQwVakBjySIFkHwWu7kMR/TF35JMjiVEEALr/ypPrLXlPtGtri4DxbDqZ1FUZX04vTUD4BZ2njobjl9PEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABpklEQVR4nHWQQYiMYRjHf8/7vt9gGYzDzuxkTxQXIQ4OSErtwU1qk5VyWcV1C2XjQC72wNGF7IGWHJQS2nBzWTdJbNgks4e11My33/f9HXboncw8x/fX7/9/3sfGzpZXe2Ph+4/534uLv5ot80lff62vXp07FnZtzM0+jb1rtrKQhOB9kqxaUxk5WGjDBYaKYkkXCURj1Btq6ircVlNXKDkzMzPnnHMljivVZICBL9ITXIdY/az0nEHgtLQwGNPAeb3fhzeMdbPSmajUAqPPKgQDPOPSa2wZ+OAxfIJvNww2pL14bPmhUsactWM816VJnBlW23PiTutmWwNwbPmp1k5s/bW5XMr0MN7Oc0u6y9qZb4+ff8gyTcXQsWNJxeYbEzhWbh99dAkjpg+Uz04HQnyLf7kHlOo+HswFb53UeCq9ddj/IngOS+k2uqQC8Eq6HP2vUz0qfSx3zzWYlkZ6qI79mV52N8EzJQ31bD0kveihGsmMdKS7aiUmpDc+dh1gBqigQbr7VJdDuBX9m07OK9fXgUg1TFuHa5VyrV5Ncwth+J7P/8I/rq2aXzuG/zEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABR0lEQVR4nH2SsU5CMRiFz2mLDCxowkBCQojxAdx9EhPjG/garg4+gHFyIDHRzScwxk0nWFCieAnkGi6C99L2dyFwqcA/NGm+/5z+PS1rZ4flHWMKBaOV0Uob5a23afu+2Saaiawt+3IMzhQAEMsVgADgxykFG0omjyEUmQshMjVBPxfWmA2MMM/sZDSz6TRJkiTuPGB1xrujcqm4aDfdat6585QBUCAAetUc522d1VprEKBYr26SPPNwzjnvnLOeIFoHOTjsZT7L0t/B59vrM4DW+vgkulDBPUVknh8rJ/FmpZv9S0gEAgFBatkcn4uuAjj9noxGcTyI+lF/2A3OvCwV9bI1UGY/AKkACMQHkARE/HqlrLy9wpZSmlug87ld8KHMeQXiAZIQCVzUezel1loRoIq+VmfHbr2x36jXqnt+3L6+7eXhH5m77iC//wE5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA0klEQVR4nK2SsQ3CMBBFfxJLVLBEGmZBYgwGYA9mYAAKqKioEB0SBQMglAGQEKAQAnefgpgQHAsh+I1lvzvd97fBWl2TUbcBFDupSqmcxwHhkURjAwAM0s7RvJcxA0kqD00EbrMp1giRM4AWCsSdHvr8fITmWWQN0YUKFqeGarkNYTDc5QTAkyKEViEkVQCQ7XKyyJ6XeSgXm7ly1bY+3Re5cfpqiMGll8jVTmAeatn5VbbUKvxztj9A7wcDypBr4Tq8qbc7XlJ8CQGt/mxz3tfCO23jr8oJyqnWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABQElEQVR4nHWTv0vDQBiGn++SWGMFQYLVwclJEBfBSt2LQzcF/4VOjt1dha6Cg47iIjorODo5+AeoS9GhW6lTm9znkDNN0+adjnvufb8fcKxdfQ10jhId1gWWagfdDRWVy5dFBcBEm/sN658AGNqaqNoagpOh+a2nBjC8uRvfyZPg6YKqASwDBLDETkkSczMKfeZLGbY+yyDIM2VQUKMlUFAspqRkGEAeZkOKMf59By8PdXKwx0ce5BuS/3Ow2uzSQx1M/R9JavQrYvnNnGm5696CIF5YqdR3CV2MYVttbvFC8KBnWUPppecW7wXjc5YLsQmx61jeO69YF7szFZu9Ni4wG9KN6pkstkpRycQ5CylAKYEhUCybQvFZB5AVPClCHdMClEN0xh017lRVrf6096Jp69ZjP1br/sCofxvlGvsD9miHMoFf0vwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABtklEQVR4nG3RMWtUQRTF8f+deY+3GzS6uBICghoRtIhIXASNiAoKQf0M2gb7fIHgN7ARxCqFVuliKQS0ESEiahRXlygKIiYo7jPMzL0WmxcfcU/7Y86cYQQA8XG88/FzPypI0Wg0m42xzvl7GYC3OHNnovxWakyS50VRFHnOrYeAeFr3TdVqSbZxBQ8IV3sWk2mqEjZtrUMGwuFFq06lEEKImuz5QTIAN/fkWXe9XhpfzY1udQIUE8ttE3VPV5r9H+9fvA4OBQDnPJPB1JJdwwNI5gDIQPEcz5I3t/lOCsU0JasQhBMYJr2elQYgjT8VOmESAX5eGhsZ2bVn9/4jtx+4waXecaO02ly1+a2hkrF3oaIUYyhjvMlgEMKFrkU1M1NNKQT7dX2wBGjfrTea2pvT25bNjC+12odygP7v8GX10WLpI9sR9n01NbPLeVNA3D9yPuOcqal9byH4TGqmCaZRlLfrIpKi1RCMs4CxiteaAA5Jo1MIwgo74xCOHcAhvMT+Q8cZIuo2PgxBZRqS8mmt+uD6KxtdCxYWjiI7Dc9JNVs6NYQgY9YeXwTnhqBjfha8H0L8BWRSBqFjOlPmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABcElEQVR4nH2RsUqcQRSFvztz519ZN2DEiBgURIzLIsa0KU1hJ9ZC0qbwDRSLgGUKwTp18gKieYxUWtqYSkFZ4+Z3/5lrocvOxjWnGw7fmXNmZOmg3r62GGOqDMMEQVwIwY3t683p68UPDFGlRwJieztdB3vnhQGhNlK8nH83Wda+IFowd2PJ0gyuRwljO7e2D0D9wpJZk0JVVTWoF8+ufQeE2oUls/k+CcqS/dL+2fI6kbOPVxk5l5MI0CctDSwxPM/EOhIxT/KEEEJQVR/S6sk6LiNL7h5hia+2mxHJzM+XwQCpFS8W3o/z+7HXQ9tcMcZWHms/2mogIRTjzSk63ZxM00hvY2Or7LZwmTlLUFVV78XxzVbwWaGKqtfWp5+tNjY0tv8Uz8j9z0w9U//Ny2PrHsAPv7PuAWk8JZ0PvGkATKDeD5opdvlElMgmVYwDprxdHt1YMwE4Pr6sDtuSffpXq1L5t/On0ynNki3m4+4BGeifFBi4TnsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB1klEQVR4nG2Rz0tUURzFP/d732jNKGG/CBujNJIgJFdCCzcFbfoPWkctoo2boEUrIVrZX9Aqg1obRJELkwoiihDbRNjPkaSwIRvfe/eeFm/eTEpn++Hcc+75AmAM/1BQyNLNzZYkKbTyoEYCIJqPx0YxA/iw4ans7ycyR6neGeVSrvlaUqnUhqbSECbbyPVyUZmUaQoPwH0tV62Ayt0YIM9Th3OuYgvh+UYbEpjAkFt5qygpxoZ/WSYaw38Ulelu8WrFH30wUkLP+aLPBRLAlZa2TiNk6SIRTJdve+fKsvS+U1DQUo+ZVVw9fDEHSQF1bESOaPMpELlpd6IPbWhxMgke4/WenVYbvXSWR511MO4pk6S1bz9/ZVL82Ec3svZJQVJspa1camkWX7Y1TtZlBG4NHT50/NyLHhY6RhKuKpOCiqlPpGG8+0fjoXJFNXY7c4kfXF/d1XEa+74rKtccBkZdSwUrxhrfGw3xBItE93XmFU6dyBvKFGOYaN/yXzm3qFxRKzvaSb7TBqP+W1GZZrsVO1cxd6oaHY5n/4HoDBGM5W0MPPSsKEoKB+juUtKD08pCHvJw/cjANjb9Zl2lmp+vbflMcqVv/f1aM1W1Wu0fHFjdYvwLtvr0eIUIDbsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAeklEQVR4nM2Quw2AMAxEX0gEDUNRsxrjMAENDUPQsQQxpuOnBBASAnfW853OZxRECY43EQCAQ003pMETQUctcTElJNiwuQMmRIIwOcnzFnSA3b+isoWC9xGloUjzadVlfbN0qocZtcbeCyS2ave2LNtV8c9e+aL438EZcqA8OyqW4VQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABQ0lEQVR4nG2RTUoDQRSEv9fdSnDjIijoNgqKiSJ6CsGt59OV1/AARiRE/IkuBEGCEReiEs28cpFxEmdSyy6qXvE1QOREI5Xl6gfArYlRlrgKELTcmGmeBzDWF1U1jXYCYwePANJU0L66CcQO41f7l3+9T+BsY0AWj09rWZGMgyEY9YFc0kgHpbMJU6MuA8XsIQafuuqJ4Nt4BNnTk09NEiRgFwHi+gOVajNaOYLHlVjswfuAsdiXS5K+h4U+h2cYydRYysvmJoUerglZCt6yLBYb/kxrYyTL94xxFgToIMIo5/Nf9trDCVrYIJQ9cfdmItFYHv+XDm8LPrL38a0jjSRlep6vlKcJn580DVZAyvmIjvBSMtQ287EXlVbC2ioGRO9WgoRmzQ1kL73SlwBhDwHOzbtVzf18zyWxenMLA2zWHn4BCGerQTmKr60AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABWElEQVR4nH2RvU5CQRCFz+wuIKAmVlR0FlZWvobPYnwB38DexMbKzmhtYuisLKAjGBv/DRER+b13Z8biXpcL3nCq3T2ZOd/M0sF+qVqplK2zxlmIchTNRsP+58v9bRNNTcTMzCyiQf7K1VRBAAyWpHboNokAKJ3FW9XqerlQLBQdx5P+x8PlDcUOANjWn0lhrDHGEFgiBuBc2sXCiIqErmRFnKRhDEnC/yI94GblLMQik5ksU2bN8SpztMJ0w0DrMokKUcD9QCmh9Qs4NK80OBna5FWiaNp9bd+NSXGumV0HCbd2YNwgbeN96EdE1u9ut+dAYY8AoJPeaQPqvpMbdY5iAwCqEk/HX08jCibQv/DIyigQMjcKbMOQSP7H9dM5i6yLpQBMN0Us5azPvKWHNcoxB+kP638Pxj+SAsC75JijBgTicR3nlGJPvYh26nkecMi91nENOUC/9EnAhDoxA9oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAArElEQVR4nN2RMQ7CMBAE72yDhAQSD6DL96hTUyP+QEPNV+jo+AENEgIU4lua2PgcJ6LmKkvj3T2vaYMWxRGcDI2MCwdBRuB8hD0L0KyD4Ms1w5icOyi2PhoZzJwWjCMESU/521M4vwd8YVOwdcF9WyulLHZ744JpVSmRt6sk0yODbQKtjmMyCXw0rJTLV4Ri1oe52pafJKF4ur9vw90aYuVLSCAR8u8e7/aP4Adas0rVM2iyMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAkUlEQVR4nN2ROw4CMRBD7WUokJDYi3BCxDW4FyV3oERCK2Ziml2Uj4KAkjQpXmzPOBQ6R7wOPQYANt/ROIjBri3wsPnV8TKkGk6QJIX27zJHW0WT+hrI1UB8tApJlp4ZdHlfuRurge4TsJRwK4Vuh5P5otzWlpsis1J6Bq1gWGfKplvxjMBv3aaUffbX3f4RfAIQQUAZUTrg0QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAfklEQVR4nNWRsQ0CQQwExz4nICF9KXRAH6TEVEZIDdTwHVDBiwRsE3x4PhECTkeWvbOSDCZlNrydb7soqCzkMw+0etmANoBpgONeUh398y24RjHpSQRrlFcdxVCO+22nLzaXWSVT7o/+sk+nq310q2hRXCYGBFFV9oNu/wu+ASWmJtWwWWAWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACFUlEQVR4nG2RT0jTcRjGn/f9fqftT/ttFSXOTGfDHEKswwglRyOGQphQdOgWeSw6JHToVFBBUNAlKC9JHYJO0X+tDlHQpQLXbNl0YTM1y6VDptt+328Htym69/q8L8/neV5gzZCQTEREAo01IBAAWdjb2zL7efjTb9Llxc7YTyKwFoXIve2KkY6++ziSKLiqpcthOfX1ukmA9LV1HTIepL1NHqumqS/JzOLcZHbq7MAb6Qy1HtungOgVkKu2vtnfHLLygth2qffWd2rxvOq5vwniZXeu5Oiuqas1zLmWhwDD/UQv68sASAghxCq9JFY2OyzRIQDaBAACgaDBJiAQGNP6pAUbR4Kw06tmkvm1ZRTNmQrUAb62aBCVxXIVjD0JnTrqZBCDmAFYHWUNrU24PX3gdKddQSsFwDiHErJ9QP/qQlwXBs8cDO42mNA34Sh5eNP6hs/yQs9rnR+7ez5C+2/2XYRlJVT49eSJWPZIYnxrQ1soYGTGF/68T47EWQESQQy+3bz0aEn9HR3S7vbDPnbNTDfGCQCqn+V6tjSAmFhILuaURR7HxDdbJFTCIyGYGVjhYd6Ryvv/lXJr01RKlWpgUTVreDIVigXADFta1he7WS8CdWYuAFKqkjhv7+7f1WD6w0HQOlEuH093PHc+fvph+MfqN8qnsupCqr+90q8hrVct4+FR0qw33EHK7J2YZjIr8OA/Oee3bKA8k+UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAfUlEQVR4nGP8zwABf/8xoIEP+1lgTGZmdEl2AbjkimfoWr/fYfgPBUboGhkYGOA6Bbh+ocv9h0v+/fMHQycTFtOoIAm3k5GREbeD/vz9jy6J0Mkn8BtN6u8XRpj6j+hyDJec4Tr5MQwVYEAK279okk8ZyA3b/38HImyHkSQAd9czYr/FdqMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4.加载数据，验证数据集，查看一下A目录里面前20个数据图片\n",
    "fn = os.listdir(\"notMNIST_small/F/\")\n",
    "for file in fn[:20]:\n",
    "    path = 'notMNIST_small/F/' + file\n",
    "    display(Image(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三、现在我们将要把图片数据转换成为像素，并且对数据进行Zero Mean是数据更加正则化，整个数据集会被加载到一个3D数组中（图片index，x，y）。\n",
    "如果有些图片不能读取，我们就直接忽略掉。\n",
    "由于可能不能一次性将所有数据读取到内存中，我们会对每个目录图片分别处理，并将处理完的数据存储到对应的pickle文件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./notMNIST_large/A.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/B.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/C.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/D.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/E.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/F.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/G.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/H.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/I.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/J.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/A.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/B.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/C.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/D.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/E.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/F.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/G.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/H.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/I.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/J.pickle already present - Skipping pickling.\n"
     ]
    }
   ],
   "source": [
    "# 5、将图片转换成像素 \n",
    "\n",
    "image_size = 28  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "\n",
    "def load_letter(folder, min_num_images):\n",
    "  \"\"\"Load the data for a single letter label.\"\"\"\n",
    "  \n",
    "  image_files = os.listdir(folder)\n",
    "  dataset = np.ndarray(shape=(len(image_files), image_size, image_size),dtype=np.float32)\n",
    "  print(folder)  \n",
    "\n",
    "  num_images = 0\n",
    "  #for image in image_files:\n",
    "\n",
    "  #for image in image_files: \n",
    "  #由于内存不够，只能选择分批处理 \n",
    "  print('Totol PIC Number=',len(image_files) )   \n",
    "  for image in image_files[:5000]:\n",
    "      \n",
    "    image_file = os.path.join(folder, image)\n",
    "    try:\n",
    "      image_data = (ndimage.imread(image_file).astype(float) - pixel_depth / 2) / pixel_depth\n",
    "      #image_data = (plt.imread(image_file).astype(float) - pixel_depth / 2) / pixel_depth\n",
    "      #image_data = plt.imread(image_file)    \n",
    "        \n",
    "      if image_data.shape != (image_size, image_size):             \n",
    "        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "      dataset[num_images, :, :] = image_data\n",
    "      num_images = num_images + 1\n",
    "    except IOError as e:\n",
    "      print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "    \n",
    "  dataset = dataset[0:num_images, :, :]\n",
    "  if num_images < min_num_images:\n",
    "    raise Exception('Many fewer images than expected: %d < %d' % (num_images, min_num_images))\n",
    "    \n",
    "  print('Full dataset tensor:', dataset.shape)\n",
    "  print('Mean:', np.mean(dataset))\n",
    "  print('Standard deviation:', np.std(dataset))\n",
    "  return dataset\n",
    "        \n",
    "def maybe_pickle(data_folders, min_num_images_per_class, force=False):\n",
    "  dataset_names = []\n",
    "  for folder in data_folders:\n",
    "    set_filename = folder + '.pickle'\n",
    "    dataset_names.append(set_filename)\n",
    "    if os.path.exists(set_filename) and not force:\n",
    "      # You may override by setting force=True.\n",
    "      print('%s already present - Skipping pickling.' % set_filename)\n",
    "    else:\n",
    "      print('Pickling %s.' % set_filename)\n",
    "      dataset = load_letter(folder, min_num_images_per_class)\n",
    "      try:\n",
    "        with open(set_filename, 'wb') as f:\n",
    "          pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "      except Exception as e:\n",
    "        print('Unable to save data to', set_filename, ':', e)\n",
    "  \n",
    "  return dataset_names\n",
    "\n",
    "#train_datasets = maybe_pickle(train_folders, 45000)\n",
    "train_datasets = maybe_pickle(train_folders, 4500)\n",
    "test_datasets = maybe_pickle(test_folders, 1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFCFJREFUeJzt3X2QleV5BvDr3t2zC7soAiquQASUqEgV7RlM1LRag1XGBP3HSjMptibEqdqY2hktbY1xJglN82VSY4qFABk/4geM1BqN7qQh0UhcLYr4URGJsAKLggKL7Ne5+8e+ZFbd534O5z3nvGe9r98Mw3Lufc/77Nlzcc7u/T7PI6oKIvKnLusBEFE2GH4ipxh+IqcYfiKnGH4ipxh+IqcYfiKnGH4ipxh+IqcaqnmyRmnSEWip5imHBxG7HrsKs2VksDR5aqd5aKPU26eGfW5BZOwp7vu9yNe9rWe0We/d0RSs1b2z3zw2+mXV6IWxB9CFHu0u6puSKvwiciGAWwHUA/hPVV1kff4ItOBMOT/NKT+SpCn8JAUA7e627+DUU4OlJff+yDx0YsMos96vBbNeL6W/eezVfrO+oafPrH+jY45Z3/5vxwdrIx/8nXmsNNjR0EIk/QX7a6uUtdpW9OeW/J0TkXoAtwG4CMB0APNEZHqp90dE1ZXmZ/5ZADaq6iZV7QFwD4C55RkWEVVamvBPALBl0L+3Jre9j4gsEJF2EWnvReTtKxFVTcV/26+qi1U1r6r5HOyfbYmoetKEvwPApEH/npjcRkTDQJrwPw1gmohMEZFGAJcDWF2eYRFRpZXc6lPVPhG5BsCjGGj1LVXVDWUbWa2pM/rhkXZYVH+6ttDeyc3BWpatvJhc5BqDP2q029X3TrXbWu/e9lCw9uejvmIeO/rOp8y6+XwYJlL1+VX1YQAPl2ksRFRFvLyXyCmGn8gphp/IKYafyCmGn8gphp/IqarO569p0Tn1KXr5kXnpOxbMMuvHrtpk1t8+pfQ59X2wrzGor+HXh27tNeuj68LrHCz++vfNY+/5B/t78utbzjTrzavWmnXz+ValXbRq9ztLRBXF8BM5xfATOcXwEznF8BM5xfATOSVapbYCABwuYzWz1XtjUzAjq63u+ctPBGtjnraXx0bO7qje+egys76+NzxlFwCm57qCtSPr/S6Vbk1XjrU4myRn1n/8zodWrHuf/5p9mlnv63gzXEyxlPtabcMe3VVU75ev/EROMfxETjH8RE4x/EROMfxETjH8RE4x/EROfXSm9MZ6o7FdUyPXAXztliXB2tX3f8E8ViKXUoypt/v4eekx6811fnv5FmvZ8e6CvQNwbIvubz1+sVmf1mFP6bV2Ada+yNjKhK/8RE4x/EROMfxETjH8RE4x/EROMfxETjH8RE6l6vOLyGYAewH0A+hT1Xw5BlXSWOrtPn2sd9p90Rlm/YLmZ4K1JZfdbh47QuwlpgF77nhsK2tr3nolt9gezpok3SUuKz/zA7O+8IfzzHr/q8Zy7Cnm8x+Kclzkc56qvlWG+yGiKuLLApFTacOvAH4hIs+IyIJyDIiIqiPt2/5zVLVDRI4G8JiIvKyqawZ/QvKfwgIAGAH7GnYiqp5Ur/yq2pH83QlgFYAPbXCmqotVNa+q+Rya0pyOiMqo5PCLSIuIHHbwYwAXAHihXAMjospK87Z/PIBVMtCWaABwl6o+UpZREVHFlRx+Vd0EwF6cvJpS9rO3zI6s62/IN9rz7dP2lGN9fjp0sesfetVe/2Fmk/0j7M5PjTfrY40+f9prVorFVh+RUww/kVMMP5FTDD+RUww/kVMMP5FTw2vpbmOqo/ba7ba6Fnt562tnl36JQn1sCiYNO7FWX6z92tVqPyfGWsVIqw9s9RFRGgw/kVMMP5FTDD+RUww/kVMMP5FTDD+RUzXV55dco/0JxhLVsSm9m5dNNevXjXnCrFt93yaxl97OkrWsdzEKSLdMdJ2x13UtLyue9tqN/MX2ujY7vmFcs9JjX7NiLu19CN+u2n30iaiiGH4ipxh+IqcYfiKnGH4ipxh+IqcYfiKnaqrPr32RrayNrYkbpk42D/3JHy+LnN2eQ231q2PS9tpj/fA09x+7b6+Lhseu3YjN919x3Bqz/vG75gdrU+Y9Zx5bLnzlJ3KK4SdyiuEncorhJ3KK4SdyiuEncorhJ3Iq2ucXkaUALgbQqaozktvGAvgZgMkANgO4TFV3px3M9r/7pFk/5rNvBGsnHRGuAcDU3IHI2e11/dPMPY8du69gj20kIuscpLC1b59Zf7FnjFlv32+vkzD38HXB2imNI81jY9cvZLkeQJrrPgDg52fdFqxdcen15rHNq9amOvdBxTx6ywBc+IHbbgTQpqrTALQl/yaiYSQaflVdA2DXB26eC2B58vFyAJeUeVxEVGGlvm8ar6rbko+3AxhfpvEQUZWk/qFJVRXGymEiskBE2kWkvRfdaU9HRGVSavh3iEgrACR/d4Y+UVUXq2peVfM5NJV4OiIqt1LDvxrAwWlJ8wE8WJ7hEFG1RMMvIncD+C2AE0Vkq4hcCWARgNki8iqATyf/JqJhJNrnV9V5gdL5ZR4L9k6z50g/d/JDwVp8P3W7jx9j9Zxj/ebVXc1mfW9hnFn/3GFvm3Xra89/+1rz2AkrXjbrqLNn9Bd225d3/M+sq4K17nH2j4HSF1mEPl2rvbIiQ9eG8OBz3fZzWRqM2PbZ5x2MV/gROcXwEznF8BM5xfATOcXwEznF8BM5VVNLd7dsLn2h6AJiy1enW4S6W8M9lGaxp9xe/0B4mWYAmPbTD86ber9//br9f/ToFYcHa8esfNI8tj+2FbWxXHox5MnwMtQjUt2zX+Z3hFt0E1EMw0/kFMNP5BTDT+QUw0/kFMNP5BTDT+RUTfX56yI7dFtiWypnqb7b7qVvmWNP6V0/60dmfcZTfxus2ZOJAWm0r1HQnp7IPcROEH59kfrItRd19uMmsWsUzPuOvO4V7OtGNHL9g/ZG5tYWjGm7kWnU5rGHgK/8RE4x/EROMfxETjH8RE4x/EROMfxETjH8RE5Vtc8vI0eg7qTpwfqeU1P2lCuoPkVPWabvNevXzmgr+b4BoOuECj5uKefzw1hWXFP2q1OOLFP1J0wJ1qTbvuClb8vWsoyBr/xETjH8RE4x/EROMfxETjH8RE4x/EROMfxETkX7/CKyFMDFADpVdUZy280AvghgZ/JpC1X14eh9fawPuVvDa9S/Pu0u83hrK+qcpFuXP6Yhxbr/y/NLzfqk+u7IPYyyy1rLe1WHNbQeY9Z7Pt5q1t+dbK/833Vs+HE5cHRkn4ej7O/JpKPtrcnPOmqTWf/a0fcHazP/3d5WfeI3q9fnXwbgwiFu/56qzkz+RINPRLUlGn5VXQPA3lKGiIadND/zXyMiz4vIUhEZU7YREVFVlBr+2wEcD2AmgG0AvhP6RBFZICLtItLe8857JZ6OiMqtpPCr6g5V7VfVAoA7AMwyPnexquZVNd94xMhSx0lEZVZS+EVk8K9hLwXwQnmGQ0TVUkyr724A5wI4UkS2AvgqgHNFZCYGZlVuBvClCo6RiCogGn5VnTfEzUtKOdl7PTls2GL0bqfZx2fZ56831p+PmdVk7ymwL+067FLBme2xdQwi8/3rx40N1s5+9HXz2IVHPmLW+9Xu1af5nqVlPVcB+/n693+10jx25bKZwZrsLH6JDl7hR+QUw0/kFMNP5BTDT+QUw0/kFMNP5FR1t+guCArvlX7KNMtnZynWkvpIM7abnjFyS6q73l2wLxevR/j5kou0Aesir4tpn4v7jfbulaO3m8d+/ZsTgrUDX7W3XB+Mr/xETjH8RE4x/EROMfxETjH8RE4x/EROMfxETlV3i+4+QWNn6aeM9V5rVXRq6XDeazqi/+3w2q9P7TvBPPazLc+b9dF19tLdlZ7mnUYvSp/GPWXizmDt7ca+ou9neKaJiFJj+ImcYviJnGL4iZxi+ImcYviJnGL4iZyqap8/t0/R+kS4D9l/hT3vvc6Yn00VElma25qvDwAw5q3/9h/PNA896W9Os++6YD8fRozoDdYePP0O89gpOXtb9LTLhhdgHW8/pu+8F76+oT/ymAzGV34ipxh+IqcYfiKnGH4ipxh+IqcYfiKnGH4ip6J9fhGZBGAFgPEYmHm+WFVvFZGxAH4GYDKAzQAuU9Xd5n29ux9NP28P1q/a+ilzLHdMeiJYS7MlMqUQ217cWN++8dHwcwEAjnvEvsZAGuynr/aFrym5qu1y89hHT37IrPdF5uPXR15X06xNceYxbwRrW3M9Rd9PMSPoA3C9qk4H8AkAV4vIdAA3AmhT1WkA2pJ/E9EwEQ2/qm5T1WeTj/cCeAnABABzASxPPm05gEsqNUgiKr9Deu8hIpMBnA5gLYDxqrotKW3HwI8FRDRMFB1+ERkF4AEA16nqnsE1VVUEVqITkQUi0i4i7b3oTjVYIiqfosIvIjkMBP9OVV2Z3LxDRFqTeiuAzqGOVdXFqppX1XwOTeUYMxGVQTT8IiIAlgB4SVW/O6i0GsD85OP5AB4s//CIqFKKmdJ7NoDPA1gvIuuS2xYCWATgXhG5EsDvAVxW1BmNKaIbbzrZPHTDfzwerJ3SONI8tpZbgamXJE9xuDRGtnQupFtXXPvC02qj04Uj22BbrTwA6D/3jGDtpilL7XNHNESm3cakmZ5++bingrVfNnQVfT/R8Kvqb4DgSM8v+kxEVFN4hR+RUww/kVMMP5FTDD+RUww/kVMMP5FTVV26GyKQXLivHJvi+ZlfXR2sbZpt92271eg3I7aUMtAkuWAttoxzxaU4vfbYU0C1t/gpokMxp92ebl/X0XHuYWZ91J/tMOv3nfKDYG1iQ2WX5o5Jc3y+Mfw9aZHir8vgKz+RUww/kVMMP5FTDD+RUww/kVMMP5FTDD+RU9Xt86va87sjTr5pZ7A2pfcL5rHrLvyhWR9l9PEBu++buuebcuvxs6dvDNbW3XCWeWz3WLsv3NBlj633cLsf/rnZvw7Wbhi3xDy2uS6y1kBEvzYbtXR9/NjxhaFXtfsDaz5/7Ny/6w5v0d3FLbqJKIbhJ3KK4SdyiuEncorhJ3KK4SdyiuEncko0tnZ6GR0uY/VMSbHat7WOe+TrKPzp6Wa9ddFrZn3FcWuCtdd795nHxkzJ2XPLvYqtwdAf+Z43SfgyllgfPs36DsWwvrbYfR/f9tfB2pv/chu6N3UU1eznKz+RUww/kVMMP5FTDD+RUww/kVMMP5FTDD+RU9H5/CIyCcAKAOMBKIDFqnqriNwM4IsADk6yX6iqD1dqoAODCf9fJY32l1L3q/8169uvP80+9/3hPv8FT1xjHqpqt103nvcTs76vcMCs1xn/h3ervYe91QsHgF70m/UYa62CnNh73DcgUo90s61efuzciJz7pZ79Zv2V3qPN+iUt4WtD5rwyxzz2xK+8Eazt2l38PgvFLObRB+B6VX1WRA4D8IyIPJbUvqeq3y76bERUM6LhV9VtALYlH+8VkZcATKj0wIiosg7pZ34RmQzgdABrk5uuEZHnRWSpiIwJHLNARNpFpL0X3akGS0TlU3T4RWQUgAcAXKeqewDcDuB4ADMx8M7gO0Mdp6qLVTWvqvkcmsowZCIqh6LCLyI5DAT/TlVdCQCqukNV+1W1AOAOALMqN0wiKrdo+EVEACwB8JKqfnfQ7a2DPu1SAC+Uf3hEVCnF/Lb/bACfB7BeRNYlty0EME9EZmKg/bcZwJcqMsLBCuG2k/ak2ya7oXOPWX+rvytYG/dweCllAMjtj0ybPs8ux6Z4Wm2rZqRb/rqWxZbPth6XO/eOM49ddMdfmPWP3bfFrGuX3Qr88ZRjgzXZYE8vL+wP37dq8a3ZYn7b/xtgyGZtZXv6RFRRvMKPyCmGn8gphp/IKYafyCmGn8gphp/IqeG1dHca1rLfQHTp791XfDJYO6ot0vM9YM9peO26E8z6ES+bZbxzYrh2zqfXm8f+c+sjZv3JA8eZ9Q377Tlej78ZHtyRzeFrJwDg+1PvM+sH1J52e8l/fzlYO+mW181j+3d0mvW0zydTXWS6sXF9w9rC49iju7h0NxGFMfxETjH8RE4x/EROMfxETjH8RE4x/EROVbXPLyI7Afx+0E1HAniragM4NLU6tlodF8CxlaqcYztOVY8q5hOrGv4PnVykXVXzmQ3AUKtjq9VxARxbqbIaG9/2EznF8BM5lXX4F2d8fkutjq1WxwVwbKXKZGyZ/sxPRNnJ+pWfiDKSSfhF5EIReUVENorIjVmMIURENovIehFZJyLtGY9lqYh0isgLg24bKyKPiciryd9DbpOW0dhuFpGO5LFbJyL2drOVG9skEfmliLwoIhtE5MvJ7Zk+dsa4Mnncqv62X0TqAfwfgNkAtgJ4GsA8VX2xqgMJEJHNAPKqmnlPWET+BMA+ACtUdUZy27cA7FLVRcl/nGNU9YYaGdvNAPZlvXNzsqFM6+CdpQFcAuAKZPjYGeO6DBk8blm88s8CsFFVN6lqD4B7AMzNYBw1T1XXANj1gZvnAliefLwcA0+eqguMrSao6jZVfTb5eC+AgztLZ/rYGePKRBbhnwBg8NI3W1FbW34rgF+IyDMisiDrwQxhfLJtOgBsBzA+y8EMIbpzczV9YGfpmnnsStnxutz4C78PO0dVzwBwEYCrk7e3NUkHfmarpXZNUTs3V8sQO0v/QZaPXak7XpdbFuHvADBp0L8nJrfVBFXtSP7uBLAKtbf78I6Dm6Qmf0cWm6ueWtq5eaidpVEDj10t7XidRfifBjBNRKaISCOAywGszmAcHyIiLckvYiAiLQAuQO3tPrwawPzk4/kAHsxwLO9TKzs3h3aWRsaPXc3teK2qVf8DYA4GfuP/GoB/ymIMgXFNBfBc8mdD1mMDcDcG3gb2YuB3I1cCGAegDcCrAB4HMLaGxvZTAOsBPI+BoLVmNLZzMPCW/nkA65I/c7J+7IxxZfK48Qo/Iqf4Cz8ipxh+IqcYfiKnGH4ipxh+IqcYfiKnGH4ipxh+Iqf+HzrUGSKUIJVAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#6,验证图片质量，我们从*.pickle中随机挑选了一个数据\n",
    "# index 0 should be all As, 1 = all Bs, etc.\n",
    "pickle_file = train_datasets[6]   \n",
    "\n",
    "\n",
    "# With would automatically close the file after the nested block of code\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    \n",
    "    # unpickle\n",
    "    letter_set = pickle.load(f)  \n",
    "    \n",
    "    # pick a random image index\n",
    "    sample_idx = np.random.randint(len(letter_set))\n",
    "    \n",
    "    # extract a 2D slice\n",
    "    sample_image = letter_set[sample_idx, :, :]  \n",
    "    plt.figure()\n",
    "    \n",
    "    # display it\n",
    "    plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "四、准备训练数据、验证数据和测试数据\n",
    "我们将pickle文件读取出来进行合并，生成了对应的训练数据（Training）,验证数据（Validation）和测试数据（Testin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (20000, 28, 28) (20000,)\n",
      "Validation: (1000, 28, 28) (1000,)\n",
      "Testing: (1000, 28, 28) (1000,)\n"
     ]
    }
   ],
   "source": [
    "#7、我们将pickle文件读取出来进行合并，生成了对应的训练数据（Training）,验证数据（Validation）和测试数据（Testing）。\n",
    "def make_arrays(nb_rows, img_size):\n",
    "  if nb_rows:\n",
    "    dataset = np.ndarray((nb_rows, img_size, img_size), dtype=np.float32)\n",
    "    labels = np.ndarray(nb_rows, dtype=np.int32)\n",
    "  else:\n",
    "    dataset, labels = None, None\n",
    "  return dataset, labels\n",
    "\n",
    "def merge_datasets(pickle_files, train_size, valid_size=0):\n",
    "  num_classes = len(pickle_files)\n",
    "  valid_dataset, valid_labels = make_arrays(valid_size, image_size)\n",
    "  train_dataset, train_labels = make_arrays(train_size, image_size)\n",
    "  vsize_per_class = valid_size // num_classes\n",
    "  tsize_per_class = train_size // num_classes\n",
    "    \n",
    "  start_v, start_t = 0, 0\n",
    "  end_v, end_t = vsize_per_class, tsize_per_class\n",
    "  end_l = vsize_per_class+tsize_per_class\n",
    "  for label, pickle_file in enumerate(pickle_files):       \n",
    "    try:\n",
    "      with open(pickle_file, 'rb') as f:\n",
    "        letter_set = pickle.load(f)\n",
    "        # let's shuffle the letters to have random validation and training set\n",
    "        np.random.shuffle(letter_set)\n",
    "        if valid_dataset is not None:\n",
    "          valid_letter = letter_set[:vsize_per_class, :, :]\n",
    "          valid_dataset[start_v:end_v, :, :] = valid_letter\n",
    "          valid_labels[start_v:end_v] = label\n",
    "          start_v += vsize_per_class\n",
    "          end_v += vsize_per_class\n",
    "                    \n",
    "        train_letter = letter_set[vsize_per_class:end_l, :, :]\n",
    "        train_dataset[start_t:end_t, :, :] = train_letter\n",
    "        train_labels[start_t:end_t] = label\n",
    "        start_t += tsize_per_class\n",
    "        end_t += tsize_per_class\n",
    "    except Exception as e:\n",
    "      print('Unable to process data from', pickle_file, ':', e)\n",
    "      raise\n",
    "    \n",
    "  return valid_dataset, valid_labels, train_dataset, train_labels\n",
    "            \n",
    "            \n",
    "train_size = 20000\n",
    "valid_size = 1000\n",
    "test_size = 1000\n",
    "\n",
    "valid_dataset, valid_labels, train_dataset, train_labels = merge_datasets(\n",
    "    train_datasets, train_size, valid_size)\n",
    "_, _, test_dataset, test_labels = merge_datasets(test_datasets, test_size)\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8、将数据随机排列\n",
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "\n",
    "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)\n",
    "\n",
    "#9、将数据保存到notMNIST.pickle文件\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': train_dataset,\n",
    "    'train_labels': train_labels,\n",
    "    'valid_dataset': valid_dataset,\n",
    "    'valid_labels': valid_labels,\n",
    "    'test_dataset': test_dataset,\n",
    "    'test_labels': test_labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#10、去除数据集中重复的数据\n",
    "       \n",
    "import time\n",
    "\n",
    "def check_overlaps(images1, images2):\n",
    "    images1.flags.writeable=False\n",
    "    images2.flags.writeable=False\n",
    "    \n",
    "    start = time.clock()\n",
    "    \n",
    "    #取两个数据集中的图片对象哈希值，并把他们放到两个集合中\n",
    "    hash1 = set([hash(image1.data) for image1 in images1])\n",
    "    hash2 = set([hash(image2.data) for image2 in images2])\n",
    "    \n",
    "    #取集合交集（目的为去除重复图片）\n",
    "    all_overlaps = set.intersection(hash1, hash2)\n",
    "    return all_overlaps, time.clock()-start\n",
    "\n",
    "r, execTime = check_overlaps(train_dataset, test_dataset)    \n",
    "print('Number of overlaps between training and test sets: {}. Execution time: {}.'.format(len(r), execTime))\n",
    "\n",
    "r, execTime = check_overlaps(train_dataset, valid_dataset)   \n",
    "print('Number of overlaps between training and validation sets: {}. Execution time: {}.'.format(len(r), execTime))\n",
    "\n",
    "r, execTime = check_overlaps(valid_dataset, test_dataset) \n",
    "print('Number of overlaps between validation and test sets: {}. Execution time: {}.'.format(len(r), execTime))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "五、训练模型，我们使用逻辑回归模型来进行训练，来看看最终的准确度如何？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.891"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#11、训练模型，训练结果：\n",
    "\n",
    "samples, width, height = train_dataset.shape\n",
    "X_train = np.reshape(train_dataset,(samples,width*height))\n",
    "y_train = train_labels\n",
    "\n",
    "# Prepare testing data\n",
    "samples, width, height = test_dataset.shape\n",
    "X_test = np.reshape(test_dataset,(samples,width*height))\n",
    "y_test = test_labels\n",
    "\n",
    "# Import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate\n",
    "lg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=42, verbose=1, max_iter=1000, n_jobs=-1)\n",
    "\n",
    "# Fit\n",
    "lg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lg.predict(X_test)\n",
    "\n",
    "# Score\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：\n",
    "1、样本的质量、数据量对预测的精度，起着决定性的作用。\n",
    "2、由于内存的问题，只能将原来的样本缩小到 十分之一 。\n",
    "3、后续我将设计分布式的架构 + GPU 方式来训练，提高效率和精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
